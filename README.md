# APMAE4990 - Introduction to Data Science in Industry

### Instructor: Dorian Goldman
### Term: Spring 2018
### Location: R 7:00pm-9:30pm 1024 Seeley W. Mudd Building

### Objectives: 
This course is designed for graduate and advanced undergraduate students who wish to learn the fundamentals of data science and machine learning in the context of real world applications. An em- phasis will be placed on problems that companies such as Amazon, Booking.com, Netflix, Uber/Lyft, The New York Times and others. Despite a focus on applications, the course will be mathematically rigorous, but the goal is to motivate each tool by a concrete problem arising in industry. The course will follow an online iPython notebook where students can try out various algorithms in real time as we go through the course.


There will be no midterms or exams, but rather assignments which will be handed in periodically throughout the term. The final project will be yours to choose, but will ideally be a productionalized tool developed via a web app that uses some of the methods (or others) taught in this class to solve a concrete problem.


### Prerequisites:
 Exposure to undergraduate-level probability, statistics, graph theory, algorithms, and linear algebra is strongly encouraged, but these topics will be covered as we encounter them.


### Grading:
- 30% Assignments
- 70% Final Project

## Tentative Course Outline:

### Introduction
- Problems that arise in industry involving data.
- Introduction to regression, classification, clustering. Model training and evaluation.

###  Predictive learning (Supervised)

- Regression: Linear Regression, Random Forest, Gradient Boosting. 
- Classification: User Churn, Acquisition and Conversion. 
- Model selection and feature selection. Regularization. Real world performance evaluation and monitoring. 
- Examples from publishing, ride sharing, online commerce and more.

### Descriptive Learning (Unsupervised)
- Clustering: K means, DBScan, Gaussian Mixture Models and Expectation Maximization. 
- Correlation of features. Principle Component Analysis. Problem of dimensionality. 
- LDA and topic modeling. 

### Prescriptive Modeling and A/B tests
- A/B experiments. Causal inference introduction.
- Offline Policy Selection. How do we target who should have received treatment after an experiment?

### Intro to Data Engineering
- Map Reduce. SQL. 
- Feature engineering: Testing out new features and verifying their predictive power.
- The basics of API building. 

### Recommendation Engines and Personalziation
- Collaborative Filtering: Matrix Factorization, Neighborhood Models and Graph Diffusion.
- Content Filtering: Topic Modeling, Regression, Classification.
- Cold Starts. Continous Cold starts. Warm Starts. Performance Comparison and Analysis. 
- Introduction to Bayesian statistics. Bayesian vs. Frequentist approach.

### Reinforcement Learning
- Multi-armed Bandits. Thompson Sampling. LinUCB.
- Markov Decision Processes. 

### Deep Learning 
(if time permits)
- When and why? The problem surrounding hype in deep learning.
- Image and sound signal processing. 
- Embeddings. 



# References

 These are references to deepen your understanding of material presented in lecture. The list is by no means exhaustive.		

Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, *An Introduction to Statistical Learning*, Springer 2013		 				
			
Trevor Hastie, Robert Tibshirani, Jerome Friedman, *Elements of Statistical Learning*, Springer 2013						 					

Christopher M. Bishop, *Pattern Recognition and Machine Learning*, Springer, 2006.						 							

Cameron Davidson-Pilon, *Bayesian Methods for Hackers*, https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers	
